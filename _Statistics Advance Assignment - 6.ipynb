{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6cb568-766b-424e-b24e-3d4ce35060ef",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e771883-46e0-4353-bccf-8e344691fd82",
   "metadata": {},
   "source": [
    "- Normality of sampling distribution of means: The distribution of sample mean is normaly distributed.\n",
    "- Absence od outliers: outlying score need to be removed from the dataset.\n",
    "- Homogenity of varience: Each one of the population has same variance. Population variance in different levels of each independent variable are equal.\n",
    "- sample are indeopendent and random\n",
    "\n",
    "Violations that could impact the validity of the results:\n",
    "- Normality: The normality assumption can be violated as long as the sample sizes are equal and sufficiently large. However, the samples must be symmetrical or at least similar in shape.\n",
    "- Outliers: The presence of outliers can also cause problems.\n",
    "- Homogeneity of variance: The assumption of homogeneity of variance is an assumption of the independent samples t-test and ANOVA stating that all comparison groups have the same variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c2eab-d95c-4f18-89c8-65ef99b91d1a",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b411943-791e-4084-9d46-5290b11f9dca",
   "metadata": {},
   "source": [
    "ANOVA, or Analysis of Variance, is a statistical method for comparing mean differences across more than two groups. The three types of ANOVA are:\n",
    "- One-way ANOVA: Used when there is one independent variable. For example, testing the relationship between shoe brand and race finish times in a marathon.\n",
    "- Two-way ANOVA: Used when there are two independent variables. For example, determining the effect of two factors, such as product and gender, on a dependent variable like sales revenue.\n",
    "- Repeated measures ANOVA: Used when the same subjects are measured multiple times. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f874653-9038-4cdf-8707-6db01216a586",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0101b20-40e1-43fa-b63f-1f00b02a0749",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA is a systematic procedure that splits the total variation in a set of data into non-overlapping components. This partitioning is based on the law of total variance, which states that the observed variance in a variable can be split into components that can be attributed to different sources of variation.   \n",
    "The partitioning of variance is a fundamental concept in many ANOVA analyses. It involves calculating the sums of squares for the total, error, and treatment. Only two of these sums need to be calculated because they add together.    \n",
    "ANOVA is a collection of statistical models and estimation procedures that analyze the differences between means. It can be used to determine if there is a difference between the means of different groups. For example, ANOVA can help businesses make decisions about which alternative to choose among many possible options.    \n",
    "ANOVA uses an F-test to evaluate whether the variance among the groups is greater than the variance within a group. In general terms, a large difference in means combined with small variances within the groups signifies a greater difference between the groups.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b475d-4367-4e51-9fe2-9a252591b9ea",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c7c52b-ce3a-483c-9371-00ab27585021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 60.0\n",
      "SSE: 6.0\n",
      "SSR: 54.000000000000014\n",
      "           df  sum_sq  mean_sq     F  PR(>F)\n",
      "group     2.0    54.0     27.0  27.0   0.001\n",
      "Residual  6.0     6.0      1.0   NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data\n",
    "data = {'group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "        'value': [1, 2, 3, 4, 5, 6, 7, 8, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('value ~ group', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=1)\n",
    "\n",
    "# Calculate SST, SSE, and SSR\n",
    "n = len(df)\n",
    "k = len(df['group'].unique())\n",
    "SST = np.sum((df['value'] - df['value'].mean())**2)\n",
    "SSE = np.sum(model.resid**2)\n",
    "SSR = np.sum((model.fittedvalues - df['value'].mean())**2)\n",
    "\n",
    "print(\"SST:\", SST)\n",
    "print(\"SSE:\", SSE)\n",
    "print(\"SSR:\", SSR)\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f3690-f97e-471f-8e59-36d8a9e699b0",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03519ecb-75ff-4c20-b435-a99f36075915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             df     sum_sq   mean_sq         F    PR(>F)\n",
      "C(Fertilizer)               1.0   0.033333  0.033333  0.012069  0.913305\n",
      "C(Watering)                 1.0   0.000369  0.000369  0.000133  0.990865\n",
      "C(Fertilizer):C(Watering)   1.0   0.040866  0.040866  0.014796  0.904053\n",
      "Residual                   28.0  77.333333  2.761905       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    " # Importing libraries \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import statsmodels.api as sm \n",
    "from statsmodels.formula.api import ols\n",
    "  \n",
    "# Create a dataframe \n",
    "dataframe = pd.DataFrame({'Fertilizer': np.repeat(['daily', 'weekly'], 15), \n",
    "                          'Watering': np.repeat(['daily', 'weekly'], 15), \n",
    "                          'height': [14, 16, 15, 15, 16, 13, 12, 11, 14,  \n",
    "                                     15, 16, 16, 17, 18, 14, 13, 14, 14,  \n",
    "                                     14, 15, 16, 16, 17, 18, 14, 13, 14,  \n",
    "                                     14, 14, 15]})  \n",
    "\n",
    "# Performing two-way ANOVA \n",
    "model = ols('height ~ C(Fertilizer) + C(Watering) + C(Fertilizer):C(Watering)', data=dataframe).fit() \n",
    "result = sm.stats.anova_lm(model, type=2) \n",
    "  \n",
    "# Print the result \n",
    "print(result) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a6fa89-61cb-4196-a3e9-e20630c989c1",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02 What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b6c12-9630-4f78-b6b7-7915b39f7a5c",
   "metadata": {},
   "source": [
    "The F-statistic measures the ratio of variation between group means to the variation within groups. In this case, with an F-statistic of 5.23, it indicates that the variation between the group means is larger than the variation within the groups.   \n",
    "The p-value indicates the probability of obtaining the observed results (or more extreme results) if the null hypothesis (i.e., no difference between group means) were true. A p-value of 0.02 suggests that there is only a 2% probability of observing these results under the null hypothesis.   \n",
    "Given the low p-value (0.02), we reject the null hypothesis and conclude that there are significant differences between at least one pair of group means.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6140a1-ce20-40b7-b21c-e0fb58f6b908",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860e95cd-8ed8-4c95-bc31-3b16a6dcee4f",
   "metadata": {},
   "source": [
    "Complete Case Analysis (CCA): In CCA, cases with missing data are completely excluded from the analysis. While this method is simple, it can lead to biased estimates if the missing data are not missing completely at random (MCAR), meaning that the probability of missingness is unrelated to the observed or unobserved data.\n",
    "\n",
    "Mean Imputation: In mean imputation, missing values are replaced with the mean of the observed values for that variable. While this method is easy to implement, it can underestimate variability and distort relationships between variables. It also assumes that the missing values have the same mean as the observed values, which may not be true.\n",
    "\n",
    "Last Observation Carried Forward (LOCF): In LOCF, missing values are replaced with the last observed value. This method assumes that the missing values remain constant over time, which may not be valid in longitudinal studies.\n",
    "\n",
    "Linear Interpolation: Linear interpolation involves estimating missing values based on the values of neighboring time points. While this method can preserve the overall trend of the data, it assumes linear relationships between adjacent time points and may not accurately capture nonlinear patterns.\n",
    "\n",
    "Multiple Imputation: Multiple imputation involves generating multiple plausible values for each missing data point based on the observed data and imputing them separately. The results from multiple imputed datasets are then combined using appropriate statistical techniques. Multiple imputation provides more accurate estimates and valid standard errors compared to single imputation methods. However, it requires more computational resources and may be complex to implement.\n",
    "\n",
    "Maximum Likelihood Estimation (MLE): MLE is a statistical technique that estimates model parameters by maximizing the likelihood function. In the context of repeated measures ANOVA, MLE can be used to estimate parameters while accounting for missing data. It provides valid parameter estimates under the missing at random (MAR) assumption, where the probability of missingness depends on the observed data but not on the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f1374-b749-4fd7-9a41-0ad61a7df5d3",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d4dc44-6329-4bad-8328-6248eabc4cbf",
   "metadata": {},
   "source": [
    "Tukey's Honestly Significant Difference (HSD): Tukey's HSD test is used to determine which specific groups differ significantly from each other following a significant ANOVA result. It controls for the familywise error rate, making it suitable for situations where multiple pairwise comparisons are conducted. Tukey's HSD is appropriate when you have equal group sizes and homogeneous variances.\n",
    "\n",
    "Bonferroni Correction: Bonferroni correction adjusts the significance level for multiple comparisons to maintain an overall alpha level. It is a more conservative approach compared to Tukey's HSD and is suitable when the number of pairwise comparisons is large. However, it may have lower power compared to other post-hoc tests.\n",
    "\n",
    "Sidak Correction: Similar to Bonferroni correction, Sidak correction adjusts the significance level for multiple comparisons. However, Sidak correction is slightly less conservative than Bonferroni correction, which can increase power while still controlling the familywise error rate.\n",
    "\n",
    "Dunnett's Test: Dunnett's test is used when comparing multiple treatment groups to a single control group. It adjusts for multiple comparisons while focusing on differences between treatment groups and a control group.\n",
    "\n",
    "Scheffé's Test: Scheffé's test is a conservative post-hoc test that can be used when the assumptions of homogeneity of variances and equal group sizes are not met. It provides a wider confidence interval for each comparison, making it less likely to incorrectly reject the null hypothesis.\n",
    "\n",
    "Fisher's LSD (Least Significant Difference): Fisher's LSD test is the least conservative post-hoc test and is appropriate when assumptions of equal variances and equal group sizes are met. However, it is not recommended for use when conducting multiple comparisons due to its inflated Type I error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136345f-9159-4bad-9caf-03731a7351c9",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d94a1198-1d6b-417e-9b40-924ccd94f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 16.574213049400626\n",
      "p-value: 3.2283781469409867e-07\n",
      "There is a significant difference between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random weight loss data for three diets: A, B, and C\n",
    "weight_loss_A = np.random.normal(loc=5, scale=2, size=50)  # Mean=5, SD=2\n",
    "weight_loss_B = np.random.normal(loc=6, scale=2, size=50)  # Mean=6, SD=2\n",
    "weight_loss_C = np.random.normal(loc=4, scale=2, size=50)  # Mean=4, SD=2\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(weight_loss_A, weight_loss_B, weight_loss_C)\n",
    "\n",
    "# Print F-statistic and p-value\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723f9ec-8d45-4eb1-aa60-e11a13eae264",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01113f9-54e3-4b62-9144-edacc7731acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        sum_sq    df         F    PR(>F)\n",
      "Software              1.035327   2.0  0.136986  0.872659\n",
      "Experience            0.521940   1.0  0.138118  0.713420\n",
      "Software:Experience   2.683910   2.0  0.355113  0.704716\n",
      "Residual             90.694755  24.0       NaN       NaN\n",
      "\n",
      "Interpretation:\n",
      "There is no significant main effect of software programs on task completion time.\n",
      "There is no significant main effect of employee experience level on task completion time.\n",
      "There is no significant interaction effect between software programs and employee experience level.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random data\n",
    "n_employees = 30\n",
    "n_experience_levels = 2\n",
    "\n",
    "# Create a DataFrame for the data\n",
    "data = pd.DataFrame({\n",
    "    'Software': np.random.choice(['A', 'B', 'C'], size=n_employees),\n",
    "    'Experience': np.random.choice(['Novice', 'Experienced'], size=n_employees),\n",
    "    'Time': np.random.normal(loc=10, scale=2, size=n_employees)  # Mean=10, SD=2\n",
    "})\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('Time ~ Software + Experience + Software:Experience', data=data).fit()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "# Interpret the results\n",
    "print(\"\\nInterpretation:\")\n",
    "if anova_table['PR(>F)']['Software'] < 0.05:\n",
    "    print(\"There is a significant main effect of software programs on task completion time.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of software programs on task completion time.\")\n",
    "\n",
    "if anova_table['PR(>F)']['Experience'] < 0.05:\n",
    "    print(\"There is a significant main effect of employee experience level on task completion time.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of employee experience level on task completion time.\")\n",
    "\n",
    "if anova_table['PR(>F)']['Software:Experience'] < 0.05:\n",
    "    print(\"There is a significant interaction effect between software programs and employee experience level.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction effect between software programs and employee experience level.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e06aea-d451-4437-9fe2-b1090dcbaba9",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student testscores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0834c7bd-8dac-490e-83ff-f4ef30d2cd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "t-statistic: -4.108723928204809\n",
      "p-value: 8.261945608702611e-05\n",
      "\n",
      "Post-hoc test (Tukey's HSD):\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1    group2    meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "Control Experimental   7.4325 0.0001 3.8427 11.0224   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random test scores for the control and experimental groups\n",
    "control_group_scores = np.random.normal(loc=70, scale=10, size=50)  # Mean=70, SD=10\n",
    "experimental_group_scores = np.random.normal(loc=75, scale=10, size=50)  # Mean=75, SD=10\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "# Print t-statistic and p-value\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD) if the results are significant\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nPost-hoc test (Tukey's HSD):\")\n",
    "    all_scores = np.concatenate([control_group_scores, experimental_group_scores])\n",
    "    group_labels = ['Control'] * len(control_group_scores) + ['Experimental'] * len(experimental_group_scores)\n",
    "    tukey_results = pairwise_tukeyhsd(all_scores, group_labels, alpha=0.05)\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print(\"\\nNo significant differences found, post-hoc test not required.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dedf40-ae32-47da-9922-be6febd9bcb9",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bfc0ed3-83a7-4556-b053-b8e3749b0f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Measures ANOVA results:\n",
      "                sum_sq    df         F    PR(>F)\n",
      "C(Store)  3.596734e+05   2.0  0.202043  0.817442\n",
      "Residual  7.743782e+07  87.0       NaN       NaN\n",
      "\n",
      "No significant differences found, post-hoc test not required.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random daily sales data for three stores for 30 days\n",
    "n_days = 30\n",
    "n_stores = 3\n",
    "\n",
    "# Create a DataFrame for the data\n",
    "data = pd.DataFrame({\n",
    "    'Day': np.repeat(np.arange(1, n_days+1), n_stores),\n",
    "    'Store': np.tile(['A', 'B', 'C'], n_days),\n",
    "    'Sales': np.random.normal(loc=5000, scale=1000, size=n_days * n_stores)  # Mean=5000, SD=1000\n",
    "})\n",
    "\n",
    "# Fit the repeated measures ANOVA model\n",
    "model = ols('Sales ~ C(Store)', data=data).fit()\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(\"Repeated Measures ANOVA results:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD) if the results are significant\n",
    "if anova_table['PR(>F)']['C(Store)'] < 0.05:\n",
    "    print(\"\\nPost-hoc test (Tukey's HSD):\")\n",
    "    tukey_results = sm.stats.multicomp.pairwise_tukeyhsd(data['Sales'], data['Store'])\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print(\"\\nNo significant differences found, post-hoc test not required.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d830ba13-c4d0-460a-be22-fc8e00c292c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
