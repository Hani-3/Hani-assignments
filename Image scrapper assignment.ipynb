{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b189246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c6b1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()  # to initialize chrome driver\n",
    "d=driver.get(\"https://www.youtube.com/@PW-Foundation/videos\") # geting url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c15eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtubePage = driver.page_source  # get website page\n",
    "youtube_html = bs(youtubePage, \"html.parser\") # beautify text using BeautifulSoup library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cebbb36",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86f03c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_details = youtube_html.find_all('div', {'class': \"style-scope ytd-rich-grid-media\"}) # find class from inspect of website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "468d7d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_details = youtube_html.select(\".style-scope ytd-rich-grid-media\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8220369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.youtube.com/watch?v=a0mQ3z7KvM0\n",
      "https://www.youtube.com/watch?v=mv_0OvDB6rg\n",
      "https://www.youtube.com/watch?v=t2O7xroBwvk\n",
      "https://www.youtube.com/watch?v=DDr1vzPtBzM\n",
      "https://www.youtube.com/watch?v=auFHpTySzI0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): # Loop for first five video\n",
    "    video = video_details[i]\n",
    "    video_class=video.select('a')\n",
    "    for j in video_class: # loop to get url link from 'a class'\n",
    "        video_url = j.get('href') # get herf link feom 'a' class\n",
    "    print(\"https://www.youtube.com\" + video_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a17049",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5dcdd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://i.ytimg.com/vi/a0mQ3z7KvM0/maxresdefault.jpg\n",
      "https://i.ytimg.com/vi/mv_0OvDB6rg/maxresdefault.jpg\n",
      "https://i.ytimg.com/vi/t2O7xroBwvk/maxresdefault.jpg\n",
      "https://i.ytimg.com/vi/DDr1vzPtBzM/maxresdefault.jpg\n",
      "https://i.ytimg.com/vi/auFHpTySzI0/maxresdefault.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): # Loop for first five video\n",
    "    video = video_details[i]\n",
    "    video_class=video.select('a')\n",
    "    for j in video_class: # loop to get url link from 'a class'\n",
    "        video_url = j.get('href') # get herf link feom 'a' class\n",
    "    full_video_url = \"https://www.youtube.com\" + video_url  # to make full url\n",
    "    geturl = requests.get(full_video_url)   # make request to get url\n",
    "    video_html = bs(geturl.text, 'html.parser') # # beautify text using BeautifulSoup library\n",
    "    data=video_html.find('meta', property='og:image')['content']  # image data is available in meta data\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b2d8a",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2671c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Biggest Mistake To Avoid in Maths ðŸ˜¨ || Must Watch ðŸš¨ || Class 10th Boards\n",
      "NATURAL VEGETATION in 1 Shot || FULL Chapter Coverage (THEORY+PYQs) || Class 9th SST\n",
      "DESCRIPTIVE PARAGRAPH + DIARY ENTRY in 1 Shot |FULL Chapter Coverage (THEORY+PYQs) Class-9th English\n",
      "SURFACE AREAS & VOLUMES in 1 Shot || FULL Chapter Coverage (Concepts+PYQs) || Class 9th Maths\n",
      "REACH FOR THE TOP + WIND in 1 Shot || FULL Chapter Coverage (THEORY+PYQs) || Class 9th English\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): # Loop for first five video\n",
    "    video = video_details[i]\n",
    "    title_class=video.select('a')\n",
    "    for j in title_class: # loop to get url link from 'a class'\n",
    "        title = j.get('title') # get herf link feom 'a' class\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f9c67",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4b0f198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43K views\n",
      "3.2K views\n",
      "4.5K views\n",
      "12K views\n",
      "4.3K views\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): # Loop for first five video\n",
    "    video = video_details[i]\n",
    "    views = video.find_all(\"span\",\"inline-metadata-item style-scope ytd-video-meta-block\")  # to find views data which is available in span class\n",
    "    views = views[0].getText() # views data text is available at 0th index\n",
    "    print(views)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca81cf1c",
   "metadata": {},
   "source": [
    "Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06faaaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 hours ago\n",
      "18 hours ago\n",
      "2 days ago\n",
      "4 days ago\n",
      "4 days ago\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): # Loop for first five video\n",
    "    video = video_details[i]\n",
    "    posting_time = video.find_all(\"span\",\"inline-metadata-item style-scope ytd-video-meta-block\") # # to find views data which is available in span class\n",
    "    posting_time = posting_time[1].getText() # time data text is available at 1st index\n",
    "    print(posting_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b66c3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'data.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "# to create csv file\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "details = []\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open('data.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow([\"Video_URL\", \"Thumbnail\", \"Title\", \"Views\", \"Posting_Time\"])\n",
    "\n",
    "    for i in range(5): # Loop for first five video\n",
    "        video = video_details[i]\n",
    "        video_class=video.select('a')\n",
    "        for j in video_class: # loop to get url link from 'a class'\n",
    "            video_url = j.get('href') # get herf link feom 'a' class\n",
    "        full_video_url = \"https://www.youtube.com\" + video_url\n",
    "        geturl = requests.get(full_video_url)\n",
    "        video_html = bs(geturl.text, 'html.parser')\n",
    "        data=video_html.find('meta', property='og:image')['content']\n",
    "        for j in title_class: # loop to get url link from 'a class'\n",
    "            title = j.get('title')\n",
    "        views = video.find_all(\"span\",\"inline-metadata-item style-scope ytd-video-meta-block\")\n",
    "        views = views[0].getText()\n",
    "        posting_time = video.find_all(\"span\",\"inline-metadata-item style-scope ytd-video-meta-block\")\n",
    "        posting_time = posting_time[1].getText()\n",
    "\n",
    "        # Append the details to the list\n",
    "        details.append([full_video_url, data, title, views, posting_time])\n",
    "\n",
    "    # Write the details to the CSV file\n",
    "    writer.writerows(details)\n",
    "\n",
    "print(\"CSV file 'data.csv' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a81aa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Video_URL', 'Thumbnail', 'Title', 'Views', 'Posting_Time']\n",
      "['https://www.youtube.com/watch?v=a0mQ3z7KvM0', 'https://i.ytimg.com/vi/a0mQ3z7KvM0/maxresdefault.jpg', 'REACH FOR THE TOP + WIND in 1 Shot || FULL Chapter Coverage (THEORY+PYQs) || Class 9th English', '43K views', '16 hours ago']\n",
      "['https://www.youtube.com/watch?v=mv_0OvDB6rg', 'https://i.ytimg.com/vi/mv_0OvDB6rg/maxresdefault.jpg', 'REACH FOR THE TOP + WIND in 1 Shot || FULL Chapter Coverage (THEORY+PYQs) || Class 9th English', '3.2K views', '18 hours ago']\n",
      "['https://www.youtube.com/watch?v=t2O7xroBwvk', 'https://i.ytimg.com/vi/t2O7xroBwvk/maxresdefault.jpg', 'REACH FOR THE TOP + WIND in 1 Shot || FULL Chapter Coverage (THEORY+PYQs) || Class 9th English', '4.5K views', '2 days ago']\n",
      "['https://www.youtube.com/watch?v=DDr1vzPtBzM', 'https://i.ytimg.com/vi/DDr1vzPtBzM/maxresdefault.jpg', 'REACH FOR THE TOP + WIND in 1 Shot || FULL Chapter Coverage (THEORY+PYQs) || Class 9th English', '12K views', '4 days ago']\n",
      "['https://www.youtube.com/watch?v=auFHpTySzI0', 'https://i.ytimg.com/vi/auFHpTySzI0/maxresdefault.jpg', 'REACH FOR THE TOP + WIND in 1 Shot || FULL Chapter Coverage (THEORY+PYQs) || Class 9th English', '4.3K views', '4 days ago']\n"
     ]
    }
   ],
   "source": [
    "# To read csv file\n",
    "with open('data.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    \n",
    "    for i in reader:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bdddfe",
   "metadata": {},
   "source": [
    "Note: Deployment done on render.com. link: https://web-scrapper-youtube-deploy.onrender.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674dd466",
   "metadata": {},
   "source": [
    "GitHub repo: https://github.com/Hani-3/web_scrapper_youtube.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651acd93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
